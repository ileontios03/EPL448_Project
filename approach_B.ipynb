{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5610b2ed-1dc1-4991-8da6-19c37e67124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, RobustScaler, PowerTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17743550-58d8-4c91-9471-9fb1e3e88bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('alzheimers_prediction_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b391a458-dba4-414a-9cd5-94b263ae06a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 59426 samples\n",
      "Test set size: 14857 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop the target column and store it separately\n",
    "X = df.drop(columns=['Alzheimer‚Äôs Diagnosis'])\n",
    "y = df['Alzheimer‚Äôs Diagnosis'].map({'No': 0, 'Yes': 1})  # convert to binary\n",
    "\n",
    "# Early train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e755057-69d4-4ecf-9d76-b3dcf9e96776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_Train (59426, 24)\n",
      "Shape of X_Test (14857, 24)\n",
      "Shape of Y_Train (59426,)\n",
      "Shape of Y_Test (14857,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of X_Train {X_train.shape}')\n",
    "print(f'Shape of X_Test {X_test.shape}')\n",
    "print(f'Shape of Y_Train {y_train.shape}')\n",
    "print(f'Shape of Y_Test {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90ab45aa-514e-4ee4-983e-acfe1e378566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature groups\n",
    "num_features = ['Age', 'Education Level', 'BMI', 'Cognitive Test Score']\n",
    "features_to_scale = ['Age', 'Cognitive Test Score']  # from your V1/V2\n",
    "cat_features = X.select_dtypes(include='object').columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b55a96a-ed4a-4393-bf18-b6bcf3ab451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler, PowerTransformer, OrdinalEncoder\n",
    "\n",
    "# V1: RobustScaler\n",
    "num_pipeline_v1 = Pipeline([\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "# V2: PowerTransformer (Yeo-Johnson)\n",
    "num_pipeline_v2 = Pipeline([\n",
    "    ('unskewer', PowerTransformer(method='yeo-johnson'))\n",
    "])\n",
    "\n",
    "# Categorical encoding (Ordinal)\n",
    "cat_pipeline = Pipeline([\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "# Preprocessor for V1\n",
    "preprocessor1 = ColumnTransformer([\n",
    "    ('num_scaled', num_pipeline_v1, features_to_scale),\n",
    "    ('num_passthrough', 'passthrough', list(set(num_features) - set(features_to_scale))),\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "])\n",
    "\n",
    "# Preprocessor for V2\n",
    "preprocessor2 = ColumnTransformer([\n",
    "    ('num_unskewed', num_pipeline_v2, features_to_scale),\n",
    "    ('num_passthrough', 'passthrough', list(set(num_features) - set(features_to_scale))),\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b9fe616-7f92-44f5-8c44-dfc62eb2bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "pipeline_ada_v1 = Pipeline([\n",
    "    ('preprocessor', preprocessor1),\n",
    "    ('classifier', AdaBoostClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_cat_v1 = Pipeline([\n",
    "    ('preprocessor', preprocessor1),\n",
    "    ('classifier', CatBoostClassifier(silent=True, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_ada_v2 = Pipeline([\n",
    "    ('preprocessor', preprocessor2),\n",
    "    ('classifier', AdaBoostClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_cat_v2 = Pipeline([\n",
    "    ('preprocessor', preprocessor2),\n",
    "    ('classifier', CatBoostClassifier(silent=True, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "329798f9-53ec-442e-ad1a-f58101e7370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipelines with different preprocessing steps and classifiers\n",
    "pipeline1 = Pipeline([\n",
    "    ('preprocessor', preprocessor1),\n",
    "    ('classifier', SVC(probability=True))\n",
    "])\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    "    ('preprocessor', preprocessor1),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline3 = Pipeline([\n",
    "    ('preprocessor', preprocessor2),\n",
    "    ('classifier', SVC(probability=True))\n",
    "])\n",
    "\n",
    "pipeline4 = Pipeline([\n",
    "    ('preprocessor', preprocessor2),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define different pipelines with different classifiers and preprocessing steps\n",
    "pipelines = {\n",
    "    'svc_v1_pipeline': pipeline1,\n",
    "    'rf_v1_pipeline': pipeline2,\n",
    "    'svc_v2_pipeline': pipeline3,\n",
    "    'rf_v2_pipeline': pipeline4\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40b11f15-e45c-4d6f-b151-ead668b003f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost Grid\n",
    "param_grid_ada = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 1.0],\n",
    "    'classifier__algorithm': ['SAMME']\n",
    "}\n",
    "\n",
    "# CatBoost Grid\n",
    "param_grid_cat = {\n",
    "    'classifier__depth': [4, 6],\n",
    "    'classifier__iterations': [100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.1]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3525f765-9098-49a5-893d-77be861abb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Running GridSearchCV for: svc_v1_pipeline\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "# Register pipelines\n",
    "pipelines = {\n",
    "    'ada_v1': (pipeline_ada_v1, param_grid_ada),\n",
    "    'cat_v1': (pipeline_cat_v1, param_grid_cat),\n",
    "    'ada_v2': (pipeline_ada_v2, param_grid_ada),\n",
    "    'cat_v2': (pipeline_cat_v2, param_grid_cat)\n",
    "}\n",
    "\n",
    "# F1 scorer\n",
    "f1_weighted = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# Run GridSearchCV\n",
    "best_estimators = {}\n",
    "\n",
    "for name, (pipeline, grid) in pipelines.items():\n",
    "    print(f\"Running GridSearchCV for {name}...\")\n",
    "    search = GridSearchCV(pipeline, grid, cv=5, scoring=f1_weighted, n_jobs=-1)\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    best_estimators[name] = search.best_estimator_\n",
    "    print(f\"Best parameters for {name}: {search.best_params_}\")\n",
    "    print(f\"Best CV F1 score: {search.best_score_:.4f}\")\n",
    "\n",
    "    y_pred = search.predict(X_test)\n",
    "    print(f\"Test F1 score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0b0ed0-97db-4f19-b525-a83d1148500d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
